{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRNN_Final_Exps",
      "provenance": [],
      "collapsed_sections": [
        "mbAwmCRUWPlF",
        "nMNjAuq5B3Nd",
        "u-Fg5y_aFO3Y",
        "LUsjhHmPW427",
        "Q0BQQnmpEIih",
        "uQSdMoUqBHz4",
        "ls2E1mu7MzG4",
        "125qD04_N__9",
        "ix0M40xVD79v"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PebbleBuilds/acc-class/blob/crnn/CRNN_Final_Exps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XTY1stVzi_e"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5LihfE-zkzG"
      },
      "source": [
        "train_dataset_path = \"/content/drive/My Drive/APS360 Group Project/data_testing/pure_augmentation\"\n",
        "classes = [\"english\",\"mandarin\",\"india\"]\n",
        "\n",
        "raw_dataset_path = \"/content/drive/My Drive/APS360 Group Project/data_testing/pure_augmentation/raw_10s_3classes_npy\"\n",
        "\n",
        "aug = True\n",
        "\n",
        "if aug:\n",
        "    train_set_folders = []\n",
        "\n",
        "else:\n",
        "    train_set_folders = []\n",
        "\n",
        "model_checkpoints_abs_path = \"/content/drive/My Drive/APS360 Group Project/model_checkpoints\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU-EC3ycVz7B"
      },
      "source": [
        "## Imports and Colab Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-UZbCAxL4vy"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import ConcatDataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt \n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22eaeTRa0-2r",
        "outputId": "4e77f81a-779f-4364-9f63-ef998d0e4b7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cxAIOxyV3ZX"
      },
      "source": [
        "## Utility Function Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU2TJS5pzKxl"
      },
      "source": [
        "train_data_components = []\n",
        "  for folder in train_set_folders:\n",
        "    folder_path = os.path.join(train_dataset_path, folder, 'train')\n",
        "    train_data_components.append(torchvision.datasets.ImageFolder(root=os.path.join(folder_path), transform=data_transform))\n",
        "  train_data = ConcatDataset(train_data_components)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VSU0Km9Mgpz"
      },
      "source": [
        "# can also load in data as numpy arrays directly \n",
        "def numpy_loader(input):\n",
        "    item = np.load(input)\n",
        "    return item\n",
        "\n",
        "def generate_data_numpy():\n",
        "  data_transform = transforms.Compose([transforms.ToTensor()])\n",
        "  raw_train_data = torchvision.datasets.DatasetFolder(root=os.path.join(raw_dataset_path, \"train\"), loader=numpy_loader,extensions='.npy',transform=data_transform)\n",
        "  val_data = torchvision.datasets.DatasetFolder(root=os.path.join(raw_dataset_path, \"validation\"), loader=numpy_loader,extensions='.npy',transform=data_transform)\n",
        "\n",
        "  train_data_components = [raw_train_data]\n",
        "  for folder in train_set_folders:\n",
        "    folder_path = os.path.join(train_dataset_path, folder, 'train')\n",
        "    train_data_components.append(torchvision.datasets.DatasetFolder(root=folder_path, loader=numpy_loader,extensions='.npy',transform=data_transform))\n",
        "  train_data = ConcatDataset(train_data_components)\n",
        "  return raw_train_data, val_data, []\n",
        "\n",
        "def visualize_numpy_data(dataset):\n",
        "    batch = 27\n",
        "    num_workers = 1\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "    # Visualize some sample data\n",
        "    classes = ['english', 'mandarin', 'india']\n",
        "\n",
        "    # obtain one batch of training images\n",
        "    dataiter = iter(data_loader)\n",
        "    array, labels = dataiter.next()\n",
        "    array = array.numpy() # convert images to numpy for display\n",
        "    plt.figure()\n",
        "    librosa.display.specshow(array[0][0])\n",
        "    plt.colorbar()\n",
        "\n",
        "    print(\"Array shape is\", array.shape)\n",
        "    return array.shape\n",
        "    \n",
        "# train utils \n",
        "\n",
        "def get_accuracy_rnn(model, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for array, labels in data_loader:\n",
        "        if torch.cuda.is_available():\n",
        "          array = array.cuda()\n",
        "          labels = labels.cuda()\n",
        "        input_array = array.float().cuda().transpose(1,2)\n",
        "        out = model(input_array) \n",
        "        pred = out.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += input_array.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path\n",
        "\n",
        "def plot_graphs(iters, train_loss, val_loss, train_acc, val_acc):\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_loss, label=\"Train\")\n",
        "    #plt.plot (iters, val_loss, label = \"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "def get_accuracy_cnn(model, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data_loader:\n",
        "        if torch.cuda.is_available():\n",
        "          imgs = imgs.cuda().float()\n",
        "          labels = labels.cuda()\n",
        "        out = model(imgs) \n",
        "        pred = out.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVpWBoHbWCfR"
      },
      "source": [
        "## Data Gen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "jZHnesmCPuoW",
        "outputId": "104d6ff3-e56b-4349-9702-deb479bffa15"
      },
      "source": [
        "train_data, val_data, []= generate_data_numpy()\n",
        "(batch_size, dummy, mfcc_bands, length) = visualize_numpy_data(train_data)\n",
        "print(mfcc_bands)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array shape is (27, 1, 13, 431)\n",
            "13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qRBOzAlvNMX",
        "outputId": "a272f3b1-b522-4d1a-be7f-6e350ca9f5a8"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(dict(Counter(train_data.targets)))\n",
        "train_data.classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 126, 1: 162, 2: 184}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['english', 'india', 'mandarin']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gjvmRFTV9Ip"
      },
      "source": [
        "## Train Func"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65YgDzOvGJ90"
      },
      "source": [
        "def train_crnn_net(net, batch_size=8, num_workers = 1, learning_rate=0.005, num_epochs=30):\n",
        "    torch.manual_seed(5)\n",
        "    \n",
        "    # Obtain the PyTorch data loader objects to load batches of the datasets\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True)\n",
        "\n",
        "    # The loss function will be Cross Entropy and Optimizer will be Adam.\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    start_time=time.time()\n",
        "    best_val_acc = 0 \n",
        "    for epoch in range(num_epochs):\n",
        "        mini_b=0\n",
        "        mini_batch_correct = 0\n",
        "        mini_batch_total = 0\n",
        "        epoch_correct = 0\n",
        "        epoch_total = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            # Get the inputs\n",
        "            if torch.cuda.is_available():\n",
        "              array = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "              net = net.cuda()\n",
        "\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            input_array = array.float().cuda()\n",
        "            out = net(input_array)             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # Mini_batch Accuracy\n",
        "            pred = out.max(1, keepdim=True)[1]\n",
        "            mini_batch_correct = pred.eq(labels.view_as(pred)).sum().item()\n",
        "            mini_batch_total = input_array.shape[0]\n",
        "            mini_batch_acc = mini_batch_correct / mini_batch_total\n",
        "            train_acc.append(mini_batch_acc)\n",
        "\n",
        "            # Saving epoch accuracy\n",
        "            epoch_correct += mini_batch_correct \n",
        "            epoch_total += mini_batch_total \n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            val_acc.append(get_accuracy_cnn(net, val_loader))  # compute validation accuracy\n",
        "            n += 1\n",
        "            mini_b += 1\n",
        "\n",
        "        print(\"Epoch: \",epoch,\"Train Accuracy: \",epoch_correct/epoch_total,'Val Accuracy: ', val_acc[-1],'Progress: % 6.2f ' % ((epoch * len(train_loader) + mini_b) / (num_epochs * len(train_loader))*100),'%', \"Time Elapsed: % 6.2f s \" % (time.time()-start_time))\n",
        "        print (\"Epoch %d Finished. \" % epoch ,\"Time per Epoch: % 6.2f s \"% ((time.time()-start_time) / (epoch +1)))\n",
        "\n",
        "        if epoch>30 and val_acc[-1]>best_val_acc:\n",
        "            print(\"SAVED MODEL\")\n",
        "            model_name = get_model_name(net.name, batch_size, learning_rate, epoch + 1)\n",
        "            checkpoint_subdir_path = get_model_name(net.name, batch_size, learning_rate, str(epoch+1))\n",
        "            full_checkpoint_path = os.path.join(model_checkpoints_abs_path, checkpoint_subdir_path)\n",
        "            try:\n",
        "                torch.save(net.state_dict(), os.path.join(full_checkpoint_path,model_name))\n",
        "            except FileNotFoundError:\n",
        "                os.makedirs(full_checkpoint_path)\n",
        "                torch.save(net.state_dict(), os.path.join(full_checkpoint_path,model_name))\n",
        "        if val_acc[-1]>best_val_acc:\n",
        "            best_val_acc = val_acc[-1]\n",
        "        if n % 10 == 0:\n",
        "            plot_graphs(iters, losses, [], train_acc, val_acc)\n",
        "    print('Finished Training')\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print (\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % ( elapsed_time, (elapsed_time / num_epochs) ))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D9luc4YWNvJ"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "125qD04_N__9"
      },
      "source": [
        "### CRNN:\n",
        "\n",
        "27 Batch, epoch 40, lr 0.001, \n",
        "dataset: raw_3classes_20bands_10s_npy_CRNN, conv 32, 64, fc 25,12 hidden size 50, batch 27\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIJqqMfoQV3V"
      },
      "source": [
        "class CRNN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        # input params\n",
        "        self.name = config.get(\"name\", \"CRNN_placeholder\")\n",
        "        self.num_classes = config.get(\"num_classes\", 3)\n",
        "        # for CNN\n",
        "        self.input_dims = config.get(\"input_dims\", [0])\n",
        "        # for RNN\n",
        "        self.hidden_size = config.get(\"hidden_size\", 0)\n",
        "        self.nonlinearity = config.get(\"nonlinearity\", 'relu')\n",
        "        self.dropout = config.get(\"dropout\", 0)\n",
        "        self.batch_size = self.input_dims[0]\n",
        "        \n",
        "        super(CRNN, self).__init__()\n",
        "        # CNN layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3) #in_channels, out_chanels, kernel_size\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride \n",
        "        self.conv2 = nn.Conv2d(32, 64, 3) #in_channels, out_chanels, kernel_size\n",
        "\n",
        "        # CNN output dimension\n",
        "        self.conv_output_dim = self.dimension_checker()\n",
        "\n",
        "        # RNN layers\n",
        "        self.rnn = nn.RNN(input_size=self.conv_output_dim[-1], hidden_size=self.hidden_size, batch_first=True, num_layers=self.num_classes, nonlinearity=self.nonlinearity, dropout=self.dropout)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc = nn.Sequential(nn.Linear(self.hidden_size, 25),\n",
        "                                nn.Linear(25,12),\n",
        "                            nn.Linear(12, self.num_classes),)\n",
        "\n",
        "    def dimension_checker(self):\n",
        "        dummy = torch.empty(self.input_dims)\n",
        "        return(tuple(self.conv_portion(dummy).shape))\n",
        "\n",
        "    def conv_portion(self, img):\n",
        "        # print(img.shape)\n",
        "        x = self.pool(F.relu(self.conv1(img)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.reshape(x,(self.batch_size, 1, x.shape[1]*x.shape[2], x.shape[3]))\n",
        "        x = x.squeeze().transpose(1,2)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv_portion(input)\n",
        "        h0 = torch.zeros(self.num_classes, self.batch_size, self.hidden_size).cuda()\n",
        "\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        output = self.fc(torch.max(out, dim=1)[0])\n",
        "        return output"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}