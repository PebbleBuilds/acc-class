{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_augmentation_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oitosCCkczju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c54639-28ba-4d98-e2d6-3d171f65ef7f"
      },
      "source": [
        "import os \n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import pylab\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPxK62MvdyIx"
      },
      "source": [
        "class Augment:\n",
        "    def __init__(self, config):\n",
        "        self.mfcc_data = []\n",
        "        self.bands = 128\n",
        "        self.frames = 128\n",
        "        self.counts = {\n",
        "            \"english\": 0,\n",
        "            \"hindi\": 0,\n",
        "            \"mandarin\": 0,\n",
        "            \"tagalog\": 0,\n",
        "            \"other\": 0\n",
        "        }\n",
        "        self.samples = 1000\n",
        "\n",
        "        self.pitch_shift_count = config.get(\"pitch_shift_count\",0) #should be even\n",
        "        self.gaussian_noise_count = config.get(\"gaussian_noise_count\",0)\n",
        "        self.gaussian_noise_stdev = config.get(\"gaussian_noise_stdev\",1) #1 dB\n",
        "        self.save_npys = config.get(\"save_npys\",False)\n",
        "        self.save_jpgs = config.get(\"save_jpgs\",True)\n",
        "        self.duration = config.get(\"duration\", 1)\n",
        "        self.sr = config.get(\"sr\", 22050)\n",
        "\n",
        "        self.abs_dir = \"/content/drive/My Drive/APS360 Group Project\"\n",
        "\n",
        "        self.splits = (\"train\", \"validation\", \"test\")\n",
        "        self.labels = (\"english\", \"hindi\", \"mandarin\", \"tagalog\")\n",
        "\n",
        "        # where the raw audio files are located\n",
        "        self.audio_files_dir = \"audio_split\"\n",
        "        self.audio_path = os.path.join(self.abs_dir, self.audio_files_dir)\n",
        "\n",
        "        # where to save the generated dataset\n",
        "        self.name = self.name_generator()\n",
        "        self.save_path = os.path.join(self.abs_dir, self.name)\n",
        "\n",
        "    def create_dataset(self):\n",
        "        for split in self.splits:\n",
        "            for label in self.labels:\n",
        "                sub_dir = (\"%s/%s\"%(split,label))\n",
        "                print(\"Processing %s...\"%(sub_dir))\n",
        "                self.create_mfccs(sub_dir)\n",
        "\n",
        "    def name_generator(self):\n",
        "        return(\"mfcc_dur_%s_psc_%d_gnc_%d_std_%d\"%(self.duration,self.pitch_shift_count,self.gaussian_noise_count, self.gaussian_noise_stdev))\n",
        "\n",
        "    def windows(self,data,window_size):\n",
        "        start = 0 \n",
        "        yield start, start + window_size\n",
        "        start += (window_size / 2)\n",
        "\n",
        "    def pitch_shifter(self, speech, sr):\n",
        "        boundary = int(self.pitch_shift_count/2)\n",
        "        pitch_shifted_mfccs = []\n",
        "        for i in range(-boundary, boundary+1):\n",
        "            if i != 0:\n",
        "                shifted_speech = librosa.effects.pitch_shift(speech, sr, i)\n",
        "                pitch_shifted_mfccs.append(self.get_MFCC(shifted_speech))\n",
        "        return pitch_shifted_mfccs\n",
        "\n",
        "    def gaussian_noiser(self, mfcc):\n",
        "        np.random.seed(1)\n",
        "        gaussian_noised_mfccs = []\n",
        "        for i in range(0, self.gaussian_noise_count):\n",
        "            noise = np.random.normal(0,self.gaussian_noise_stdev,mfcc.shape)\n",
        "            gaussian_noised_mfccs.append(noise + mfcc)\n",
        "        return gaussian_noised_mfccs\n",
        "\n",
        "    def get_MFCC(self,speech):\n",
        "        mfcc = librosa.feature.melspectrogram(speech) \n",
        "        logspec = librosa.amplitude_to_db(mfcc)\n",
        "        return logspec\n",
        "\n",
        "    def resize_mfcc(self,mfcc):\n",
        "        resized_mfcc = librosa.util.fix_length(mfcc, self.bands, axis=1)\n",
        "        resized_mfcc = np.vstack((np.zeros((0, self.bands)), resized_mfcc))\n",
        "        return resized_mfcc\n",
        "        \n",
        "    def save_data(self,data,sub_dir, name_only):\n",
        "        # data = self.resize_mfcc(data)\n",
        "\n",
        "        elems = sub_dir.split('/')\n",
        "\n",
        "        if elems[1] in self.counts.keys():\n",
        "            num = self.counts[elems[1]]\n",
        "            print(num)\n",
        "            self.counts[elems[1]] += 1\n",
        "            if num >= self.samples:\n",
        "                return True\n",
        "\n",
        "        else:\n",
        "            num = self.counts[\"other\"]\n",
        "            self.counts[\"other\"] += 1 \n",
        "            if num >= self.samples:\n",
        "                return True\n",
        "                \n",
        "        if self.save_npys: # deprecated, but still usable\n",
        "            new_filename_npy = name_only + \"_\" + str(num) + '.npy'\n",
        "            path_npy = [self.save_path,sub_dir,new_filename_npy]\n",
        "            save_path_npy = os.path.join(*path_npy)\n",
        "            try:\n",
        "                np.save(save_path_npy,data)\n",
        "            except FileNotFoundError:\n",
        "                save_dir = os.path.join(self.save_path, sub_dir)\n",
        "                os.makedirs(save_dir)\n",
        "                np.save(save_path_npy,data)\n",
        "\n",
        "        if self.save_jpgs:\n",
        "            new_filename_jpg = name_only + \"_\" + str(num) + '.jpg'\n",
        "            path_jpg = [self.save_path,sub_dir,new_filename_jpg]\n",
        "            save_path_jpg = os.path.join(*path_jpg)\n",
        "            save_dir_path_jpg = os.path.join(self.save_path, sub_dir)\n",
        "            pylab.axis('off')\n",
        "            pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
        "            librosa.display.specshow(data)\n",
        "            try:\n",
        "                pylab.savefig(save_path_jpg, bbox_inches=None, pad_inches=0)\n",
        "                pylab.close()\n",
        "            except FileNotFoundError:\n",
        "                save_dir = os.path.join(self.save_path, sub_dir)\n",
        "                os.makedirs(save_dir)\n",
        "                pylab.savefig(save_path_jpg, bbox_inches=None, pad_inches=0)\n",
        "                pylab.close()\n",
        "\n",
        "        return True \n",
        "    \n",
        "    def uniform_clip_split(self, sub_dir, file_name):\n",
        "        path = [self.audio_path,sub_dir,file_name] \n",
        "        file_path = os.path.join(*path)\n",
        "        print(file_path)\n",
        "\n",
        "        # check if this is train, val, or test\n",
        "        split = sub_dir.split(\"/\")[0]\n",
        "\n",
        "        name_only = file_name.split(\".mp3\")[0]\n",
        "        speech,s = librosa.load(file_path, self.sr)\n",
        "        num_frames = int(self.duration*s)\n",
        "        for i in range(0, int(len(speech)/num_frames)):\n",
        "            start = i*num_frames\n",
        "            end = start + num_frames \n",
        "            if (len(speech[start:end]) == num_frames):\n",
        "                clip = speech[start:end]\n",
        "\n",
        "                # generate and save unaltered MFCC\n",
        "                raw_mfcc = self.get_MFCC(clip)\n",
        "                print(\"Shape:\",raw_mfcc.shape)\n",
        "                self.save_data(raw_mfcc,sub_dir,name_only)\n",
        "\n",
        "                if split == \"train\":\n",
        "                    # generate and save noisy, unshifted MFCCs (only for training)\n",
        "                    noisy_mfccs = self.gaussian_noiser(raw_mfcc)\n",
        "                    for i, noisy_mfcc in enumerate(noisy_mfccs):\n",
        "                        self.save_data(noisy_mfcc,sub_dir,(name_only+\"_noisy%d\"%(i)))\n",
        "\n",
        "                    # generate and save pitch-shifted MFCCs - both noisy and non-noisy\n",
        "                    shifted_mfccs = self.pitch_shifter(speech,self.sr)\n",
        "                    lowest_shift = -1*int(self.pitch_shift_count/2)\n",
        "                    for i, shifted_mfcc in enumerate(shifted_mfccs):\n",
        "                        shift = lowest_shift + i\n",
        "                        shifted_name = name_only+(\"_shifted%d\"%shift)\n",
        "                        self.save_data(shifted_mfcc,sub_dir,shifted_name)\n",
        "\n",
        "                        noisy_shifted_mfccs = self.gaussian_noiser(shifted_mfcc)\n",
        "                        for j, noisy_shifted_mfcc in enumerate(noisy_shifted_mfccs):\n",
        "                            noisy_shifted_name = shifted_name + (\"_noisy%d\"%j)\n",
        "                            self.save_data(noisy_shifted_mfcc,  sub_dir, shifted_name)\n",
        "\n",
        "    def create_mfccs(self, sub_dir):\n",
        "        for file_name in os.listdir(os.path.join(self.audio_path,sub_dir)):\n",
        "            print(file_name)\n",
        "            self.uniform_clip_split(sub_dir,file_name)\n",
        "        return True"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkWP46e8d1ze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "6685d4e8-1ca5-4e81-f3b3-111e516c83d6"
      },
      "source": [
        "config = {\n",
        "    \"pitch_shift_count\": 4,\n",
        "    \"gaussian_noise_count\": 2,\n",
        "    \"gaussian_noise_stdev\": 1,\n",
        "    \"save_jpgs\": True,\n",
        "    \"save_npys\": False,\n",
        "    \"duration\": 1,\n",
        "    \"sr\": 22050\n",
        "}\n",
        "\n",
        "data = Augment(config)\n",
        "\n",
        "data.create_dataset()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing train/english...\n",
            "english105.mp3\n",
            "/content/drive/My Drive/APS360 Group Project/audio_split/train/english/english105.mp3\n",
            "Shape: (128, 44)\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-7ff0253bb729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-118012965f2b>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0msub_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%s/%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing %s...\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_mfccs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-118012965f2b>\u001b[0m in \u001b[0;36mcreate_mfccs\u001b[0;34m(self, sub_dir)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_clip_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-118012965f2b>\u001b[0m in \u001b[0;36muniform_clip_split\u001b[0;34m(self, sub_dir, file_name)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                         \u001b[0mnoisy_shifted_mfccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_noiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_mfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_shifted_mfcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoisy_shifted_mfccs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                             \u001b[0mnoisy_shifted_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshifted_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"_noisy%d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_shifted_mfcc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msub_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifted_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxC2E2123kYx",
        "outputId": "6bba40ad-a720-4bbf-8a50-e60053fa50e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%shell\n",
        "\n",
        "pwd\n",
        "!cd \"drive/My Drive/APS360 Group Project\"\n",
        "!pwd"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}